{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text completion with GPT-2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPI8zYFaP3zuYxoVCtPai3r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishwvir-singh/Text-completion-with-GPT-2/blob/main/Text_completion_with_GPT-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpyGWMeuVuPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faba867a-d583-44f8-e55f-d8fda18caddc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/Colab_Notebooks_data/Text-completion-with-GPT-2"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/MyDrive/Colab_Notebooks_data/Text-completion-with-GPT-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3CPzU7BXukP",
        "outputId": "4e4e0e96-d7e9-4cbc-b8c2-0d51aa35a6a7"
      },
      "source": [
        "#Clone GPT-2\n",
        "import os\n",
        "if not os.path.exists('gpt-2'):\n",
        "   !git clone https://github.com/openai/gpt-2.git\n",
        "%cd gpt-2/"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/Colab_Notebooks_data/Text-completion-with-GPT-2/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT-LC1mWYaHE",
        "outputId": "5d9ecde3-6fe6-4745-8292-a7b4d51899e6"
      },
      "source": [
        "%ll ./"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 35\n",
            "-rw------- 1 root   551 Jun  5 18:13 CONTRIBUTORS.md\n",
            "-rw------- 1 root  2188 Jun  5 18:13 DEVELOPERS.md\n",
            "-rw------- 1 root   279 Jun  5 18:13 Dockerfile.cpu\n",
            "-rw------- 1 root   548 Jun  5 18:13 Dockerfile.gpu\n",
            "-rw------- 1 root 14754 Jun  5 18:13 domains.txt\n",
            "-rw------- 1 root  1075 Jun  5 18:13 download_model.py\n",
            "-rw------- 1 root  1403 Jun  5 18:13 LICENSE\n",
            "-rw------- 1 root  4989 Jun  5 18:13 model_card.md\n",
            "-rw------- 1 root  2827 Jun  5 18:13 README.md\n",
            "-rw------- 1 root    58 Jun  5 18:13 requirements.txt\n",
            "drwx------ 2 root  4096 Jun  5 18:13 \u001b[0m\u001b[01;34msrc\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHr_XNXgl-nS",
        "outputId": "373fcf6c-a888-490f-ad44-127de6c43f58"
      },
      "source": [
        "%ll src"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 21\n",
            "-rw------- 1 root 4242 Jun  5 18:13 encoder.py\n",
            "-rw------- 1 root 2870 Jun  5 18:13 generate_unconditional_samples.py\n",
            "-rw------- 1 root 3412 Jun  5 18:13 interactive_conditional_samples.py\n",
            "-rw------- 1 root 6503 Jun  5 18:13 model.py\n",
            "-rw------- 1 root 3166 Jun  5 18:13 sample.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REBk3H9OYaJz"
      },
      "source": [
        "!pip install -qr requirements.txt"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4cPIPncYaM7",
        "outputId": "9aaa220b-3b75-404b-db8e-c93cffa7c3c2"
      },
      "source": [
        "#GPT2 runs on tf 1.x. So lets change the tf version\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFmivtxDc-uP",
        "outputId": "f7cad611-d2d1-4059-cc5d-9f080914ba94"
      },
      "source": [
        "import os\n",
        "if not os.path.exists('models/345M'):\n",
        "  !python download_model.py '345M'\n",
        "%ll models"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "drwx------ 2 root 4096 Jun  5 18:40 \u001b[0m\u001b[01;34m345M\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnt4kIltdeSV"
      },
      "source": [
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll8nX4K6lem3",
        "outputId": "145cb595-49af-4bfd-df3a-6f561fa50978"
      },
      "source": [
        "%cd src\n",
        "import model, encoder, sample"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Colab_Notebooks_data/Text-completion-with-GPT-2/gpt-2/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usBa5yySskQr"
      },
      "source": [
        "model_name='345M'\n",
        "seed=0\n",
        "nsamples=1\n",
        "batch_size=1\n",
        "length=300\n",
        "temperature=1\n",
        "top_k=0\n",
        "models_dir='../models'"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1TGQBpT1v9N",
        "outputId": "8538b415-aa7f-4c19-9fa5-56b78166c001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.path.expanduser(os.path.expandvars(models_dir))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'../models'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UHewzhOlesD"
      },
      "source": [
        "assert nsamples % batch_size == 0"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5_Sswbmlexn"
      },
      "source": [
        "model_encoder = encoder.get_encoder(model_name, models_dir)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt9XScJNwtks",
        "outputId": "1e55129b-2c07-46df-cd51-cc6266644b41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import json\n",
        "hparams = model.default_hparams()\n",
        "print(f'Default hparams:', {hparams})\n",
        "with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
        "    hparams.override_from_dict(json.load(f))\n",
        "print(f'Model hparams:', {hparams})"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default hparams: {HParams([('n_ctx', 1024), ('n_embd', 768), ('n_head', 12), ('n_layer', 12), ('n_vocab', 0)])}\n",
            "Model hparams: {HParams([('n_ctx', 1024), ('n_embd', 1024), ('n_head', 16), ('n_layer', 24), ('n_vocab', 50257)])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft8N4haEwtnP",
        "outputId": "7b647a5e-ad2c-4f25-eeae-9d8970ed14d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if length is None:\n",
        "  length = hparams.n_ctx // 2\n",
        "assert length < hparams.n_ctx\n",
        "print(f'lenght : {length}')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lenght : 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UybiW0qzwtqH",
        "outputId": "b6d6b704-b4a0-43ce-ce1b-67c73b3fb532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "with tf.Session(graph=tf.Graph()) as session:\n",
        "  context = tf.placeholder(tf.int32, [batch_size,None])\n",
        "  np.random.seed(seed)\n",
        "  tf.set_random_seed(seed)\n",
        "  output = sample.sample_sequence(\n",
        "      hparams=hparams, length=length,\n",
        "      context=context,batch_size=batch_size,\n",
        "      temperature=temperature, top_k=top_k)\n",
        "  ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
        "  saver = tf.train.Saver()\n",
        "  saver.restore(session, ckpt)\n",
        "\n",
        "\n",
        "  while True:\n",
        "    input_sent = input(\"Pass Text to Model >>> \")\n",
        "    if input_sent:\n",
        "      context_tokens = model_encoder.encode(input_sent)\n",
        "      generated = 0\n",
        "      for _ in range(nsamples // batch_size):\n",
        "        out = session.run(output, feed_dict={\n",
        "            context: [context_tokens for _ in range(batch_size)]\n",
        "            })[:, len(context_tokens):]\n",
        "        for i in range(batch_size):\n",
        "          generated += 1\n",
        "          text = model_encoder.decode(out[i])\n",
        "          print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
        "          print(text)\n",
        "      print(\"*\" * 80)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ../models/345M/model.ckpt\n",
            "Pass Text to Model >>> Human reason, in one sphere of its cognition, is called upon to consider questions, which it cannot decline, as they are presented by its own nature, but which it cannot answer, as they transcend every faculty of the mind.\n",
            "======================================== SAMPLE 1 ========================================\n",
            " Speech is destructive of these affordances, and therefore absurd, and rhetoric to mix rationale with eloquence. There are letters, a philosopher, whose style can make up a knowledge of them better, and comprehend how manifold they are. If the acquirement of which they profess is useless, whence arises \"purchase,\" and suppose that the only end served as a sanction for this will be to render letters an educational undertaking for those whose part it may be to apply them? what has little concernments but to find out what letter is most accessible; to discern the meaning of that word whose obscurity is absolutely insupportable to speakers, and which, like the dissecting or snapping of half the width of one flesh-reeve, takes about three hides from our senses, stumbling under them with every human roll until beyond straining to write the letter on our page, it enlightens no one Uncrime was committed, or the last words so worthy of question cleverly craftiest of execution, and infinitely misapprehended. Socrates is equally guilty in a class of letters, among those written about his deceased army testator. Even Judith hangs on to mediocre letters without conversion. The seek of calling Homer, Socrates and Thucydides strictly satirical, originally invented to convey a message that they were, instead of a satire, said to be placed in the same subject. The composition of Plato's letter to Cimon persuades my philosophers indirectly , and I am their adversaries, to follow a\n",
            "********************************************************************************\n",
            "Pass Text to Model >>> Human reason, in one sphere of its cognition, is called upon to consider questions, which it cannot decline, as they are presented by its own nature, but which it cannot answer, as they transcend every faculty of the mind.\n",
            "======================================== SAMPLE 1 ========================================\n",
            " Kant was alienated from natural reason as regards rational actions. He was rather sociocultural reason, installed by society to direct private interests.\n",
            "\n",
            "According to Hegel, humanity is made rational by the Statesman, who, statesman-in-chief, seeks to fit what he has discovered to the needs of the masses. Many of those factors are in accord with the sociological truth that the task of a Stateman is congruent with our real interests insofar as these are truly our own affairs. Socialism seems no less winnowed the ever-dreaded but complete merely structurally consistent condition of State socialism; i.e. Socialists, rational and statis intelligent, are always tied to green energy and hyper-capitalism and always as opposed to reality, until they are born exactly at the \"deceptive moment\" when we need them most.\n",
            "\n",
            "Here is Marxists blathering about the sophistic and the Excellent. Giving upward due Small selection national happiness, roundly ridiculed in its sheer fluff, because gobs of invisible effort and public misery impose the requirements of this happiness upon a blessed world. Just as discriminating it from other greedy status systems is tragic. Is it better that nerve-permeable caution be disregarded for a solid structure of State Socialism, without regard of other living conditions and social classification? Is it better to turn aside from all fabrications: romanticism and technology become professions not transcendences, like medical diagnosis. Is or is not Capitalism\n",
            "********************************************************************************\n",
            "Pass Text to Model >>> Human reason, in one sphere of its cognition, is called upon to consider questions, which it cannot decline, as they are presented by its own nature, but which it cannot answer, as they transcend every faculty of the mind.\n",
            "======================================== SAMPLE 1 ========================================\n",
            " My theory does away with this problem. It may be said, that this experimentalism is subject to the naturalist-magist conception; but this is only an accounting of the above; all that it is admitting is preposterous. The idea of certain questions being hypothetical in cast should be due to the antediluvian qualities of the emulsion; but the concept of the concept of the thought as hypothetical in cast is without any grammatical propensities. It is the principle upon which judgments of possibility are forged, and at the same time renders everything absolutely determinable, not just in determinability, but in adequacy, as well as to a certain extent in sense; when looking through the imaginary lenses in which this inference is made, we are certainly led to conclude, neither with perfect certainty, nor definitely with much certainty, that by sticking toward any probabilistic principle whatever would be subordinate the considerable vagueness which follows from adopting the notion of possibility. Hence \"auditory idea,\" (impeccable, and certain of the nonfictionistic/American Epistles, p. 198.) as we know it, is realised. I contain the curious circumstances giving rise to this observation, by bringing in consciousness the baroque existence of the supernatural as a heading of the natural; that subjection here becomes an indispensable question, in order to strip away this obscure marvellous object, which they call representations of the supernatural; — by presenting it, therefore, that\n",
            "********************************************************************************\n",
            "Pass Text to Model >>> Human reason, in one sphere of its cognition, is called upon to consider questions, which it cannot decline, as they are presented by its own nature, but which it cannot answer, as they transcend every faculty of the mind.\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "\n",
            "This is the Lesson Tre 4 for my pupil. Attempting to discover an admirable another sure person in his father's carriage, or a carefully combed hair in the bosom of some one of his grandfather—so successful is our business in this direction—we come not far, if we accept as true the opinion of all reasoning, and parrot to be inspired with of labors behind closed doors, by men of high culture, eminent for their learning, rational science, and the accomplishment of an undertaking like that, which, perhaps, has escaped us in its value, the discursive uncertainty of failure. To be eminent for one's science is a nice thing; which also falls in need of fine adapting; and specialty; which boxes our brains into imperfect content; and thereby enriches us the more from the underservation of time so often set forth in precedent, before the import of the thought's message has become obvious. But the expedient of a little exacting dribbling down coordinates shafts, tack-points and limittites, will remove many difficulties in the pursuit of truth: all whence entirely diminishes that search, which so swiftly alters them, viz., from the whole (as foreseen by Virtue of Reason, vol. i. c. 21. our knowledge of things called \"existent\") to particular instances, of what belong to that general article. For plausibility of objects and creations, and from describing nouns our manner of predicating them,\n",
            "********************************************************************************\n",
            "Pass Text to Model >>> Human reason, in one sphere of its cognition, is called upon to consider questions, which it cannot decline, as they are presented by its own nature, but which it cannot answer, as they transcend every faculty of the mind.\n",
            "======================================== SAMPLE 1 ========================================\n",
            " Hence Euthyphro shows the weakness of condescension mentioning him Kamble showing the wisdom revealed by reason to be faulty. Metaphysics , Enanti. sect. 30b, Docetists, Synod on the Honour, in other words Psalm 1:9, 24.\n",
            "\n",
            "8. Prof. John Murray at dissent is a defender of general principles. He is at liberty here to acknowledge that, at least in the vital sense, Homer differed from Aquinas in arguing to the corporeal appetites which are opposed to the rational soul (J.M. iii. 5), but made considerable alterations in the distinction of good from bad. The conclusion appears, however, that this view and the one developed since Leibniz is either separate or exaggerated in them which in no respect is at variance with the treatment taken in Scripture, and so the question naturally brought up is: What must Aquinas have said, beyond his recent corroborators, in making systematic use of the definition in his statement (De facto ad flaccum etae conformet in de pergordibus Imperfectiva) that our present limitations are directed toward the POSITIVITY of the intellectual Orbites to write things by word of mouth? if there are past experiences in writing by sign ing on manuscript or reading for the Gospel, as Benedict applied to languages as machines,: v. Sc., comm. iv. 3, Ep. 4:3. On this he says (Ac\n",
            "********************************************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85Vjs6GWwtso"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XzALJeBwtvO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTXxfYDewtx0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nrF7pbVwt0o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egaZOaEzwt3O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cNOk_dlwt5-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}