{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text completion with GPT-2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0FFP7RIf+nTYoBnDZDuHC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishwvir-singh/Text-completion-with-GPT-2/blob/main/Text_completion_with_GPT-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpyGWMeuVuPe",
        "outputId": "4cb5a438-3ded-4a90-b4ca-520ecd71aba2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/Colab_Notebooks_data/Text-completion-with-GPT-2"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/MyDrive/Colab_Notebooks_data/Text-completion-with-GPT-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3CPzU7BXukP",
        "outputId": "b128af58-d245-45a4-90f4-3708a49f9b4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Clone GPT-2\n",
        "!git clone https://github.com/openai/gpt-2.git\n",
        "%cd gpt-2/"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'gpt-2' already exists and is not an empty directory.\n",
            "/gdrive/My Drive/Colab_Notebooks_data/Text-completion-with-GPT-2/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT-LC1mWYaHE",
        "outputId": "5d9ecde3-6fe6-4745-8292-a7b4d51899e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%ll ./"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 35\n",
            "-rw------- 1 root   551 Jun  5 18:13 CONTRIBUTORS.md\n",
            "-rw------- 1 root  2188 Jun  5 18:13 DEVELOPERS.md\n",
            "-rw------- 1 root   279 Jun  5 18:13 Dockerfile.cpu\n",
            "-rw------- 1 root   548 Jun  5 18:13 Dockerfile.gpu\n",
            "-rw------- 1 root 14754 Jun  5 18:13 domains.txt\n",
            "-rw------- 1 root  1075 Jun  5 18:13 download_model.py\n",
            "-rw------- 1 root  1403 Jun  5 18:13 LICENSE\n",
            "-rw------- 1 root  4989 Jun  5 18:13 model_card.md\n",
            "-rw------- 1 root  2827 Jun  5 18:13 README.md\n",
            "-rw------- 1 root    58 Jun  5 18:13 requirements.txt\n",
            "drwx------ 2 root  4096 Jun  5 18:13 \u001b[0m\u001b[01;34msrc\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHr_XNXgl-nS",
        "outputId": "373fcf6c-a888-490f-ad44-127de6c43f58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%ll src"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 21\n",
            "-rw------- 1 root 4242 Jun  5 18:13 encoder.py\n",
            "-rw------- 1 root 2870 Jun  5 18:13 generate_unconditional_samples.py\n",
            "-rw------- 1 root 3412 Jun  5 18:13 interactive_conditional_samples.py\n",
            "-rw------- 1 root 6503 Jun  5 18:13 model.py\n",
            "-rw------- 1 root 3166 Jun  5 18:13 sample.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REBk3H9OYaJz"
      },
      "source": [
        "!pip install -qr requirements.txt"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4cPIPncYaM7",
        "outputId": "9aaa220b-3b75-404b-db8e-c93cffa7c3c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#GPT2 runs on tf 1.x. So lets change the tf version\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFmivtxDc-uP",
        "outputId": "f7cad611-d2d1-4059-cc5d-9f080914ba94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "if not os.path.exists('models/345M'):\n",
        "  !python download_model.py '345M'\n",
        "%ll models"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "drwx------ 2 root 4096 Jun  5 18:40 \u001b[0m\u001b[01;34m345M\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnt4kIltdeSV"
      },
      "source": [
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll8nX4K6lem3"
      },
      "source": [
        "from src import model"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOmBuAT5lepd",
        "outputId": "5aac4ba7-5cc6-4ae8-cd9b-a57f1975b323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "help(model)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on module src.model in src:\n",
            "\n",
            "NAME\n",
            "    src.model\n",
            "\n",
            "FUNCTIONS\n",
            "    attention_mask(nd, ns, *, dtype)\n",
            "        1's in the lower triangle, counting from the lower right corner.\n",
            "        \n",
            "        Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
            "    \n",
            "    attn(x, scope, n_state, *, past, hparams)\n",
            "    \n",
            "    block(x, scope, *, past, hparams)\n",
            "    \n",
            "    conv1d(x, scope, nf, *, w_init_stdev=0.02)\n",
            "    \n",
            "    default_hparams()\n",
            "    \n",
            "    expand_tile(value, size)\n",
            "        Add a new axis of given size.\n",
            "    \n",
            "    gelu(x)\n",
            "    \n",
            "    merge_states(x)\n",
            "        Smash the last two dimensions of x into a single dimension.\n",
            "    \n",
            "    mlp(x, scope, n_state, *, hparams)\n",
            "    \n",
            "    model(hparams, X, past=None, scope='model', reuse=False)\n",
            "    \n",
            "    norm(x, scope, *, axis=-1, epsilon=1e-05)\n",
            "        Normalize to mean = 0, std = 1, then do a diagonal affine transform.\n",
            "    \n",
            "    past_shape(*, hparams, batch_size=None, sequence=None)\n",
            "    \n",
            "    positions_for(tokens, past_length)\n",
            "    \n",
            "    shape_list(x)\n",
            "        Deal with dynamic shape in tensorflow cleanly.\n",
            "    \n",
            "    softmax(x, axis=-1)\n",
            "    \n",
            "    split_states(x, n)\n",
            "        Reshape the last dimension of x into [n, x.shape[-1]/n].\n",
            "\n",
            "FILE\n",
            "    /gdrive/My Drive/Colab_Notebooks_data/Text-completion-with-GPT-2/gpt-2/src/model.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UHewzhOlesD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUng6UG9levE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5_Sswbmlexn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}